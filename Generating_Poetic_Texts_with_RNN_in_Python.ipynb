{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "97xoEOMG7VxF"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential # Fixed typo: tenforflow to tensorflow\n",
        "from tensorflow.keras.layers import LSTM, Dense, Activation\n",
        "from tensorflow.keras.optimizers import RMSprop\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filepath = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GD0lXpoB75Og",
        "outputId": "991673fc-5d35-4218-a1e6-2f414f7a1cdc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
            "\u001b[1m1115394/1115394\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = open(filepath, 'rb').read().decode(encoding='utf-8').lower()"
      ],
      "metadata": {
        "id": "HHNU5nHR8LVv"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#For training data\n",
        "text = text[300000 : 800000]"
      ],
      "metadata": {
        "id": "79GjNxex94n7"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "characters = sorted(set(text))"
      ],
      "metadata": {
        "id": "DEVzPKJD-H1D"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "char_to_text = dict((c, i) for i, c in enumerate(characters))\n",
        "index_to_char = dict((i, c) for i, c in enumerate(characters))"
      ],
      "metadata": {
        "id": "HuVdSIYB-j5i"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SEQ_LENGTH = 40\n",
        "STEP_SIZE = 3\n",
        "\n",
        "sentences = []\n",
        "next_characters = []\n",
        "\n",
        "for i in range(0, len(text) - SEQ_LENGTH, STEP_SIZE):\n",
        "  sentences.append(text[i : i + SEQ_LENGTH]) #Corrected the slicing syntax\n",
        "  next_characters.append(text[i + SEQ_LENGTH])"
      ],
      "metadata": {
        "id": "rXsrBliSEpUf"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "x = np.zeros((len(sentences), SEQ_LENGTH, len(characters)), dtype=bool) # Changed np.bool to bool\n",
        "y = np.zeros((len(sentences), len(characters)), dtype=bool)"
      ],
      "metadata": {
        "id": "YWI_wf4yHoqc"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, sentence in enumerate(sentences):\n",
        "  for t, character in enumerate(sentence): # Change sentences to sentence\n",
        "    x[i, t, char_to_index[character]] = 1\n",
        "  y[i, char_to_index[next_characters[i]]] = 1"
      ],
      "metadata": {
        "id": "Ik5naeajH6Mu"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(SEQ_LENGTH, len(characters))))\n",
        "model.add(Dense(len(characters)))\n",
        "model.add(Activation('softmax'))"
      ],
      "metadata": {
        "id": "tvhN7R2oKrkl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0762f65b-5f5c-42d0-8f88-a7bcfdb1119a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Correct the argument name from 'optimizers' to 'optimizer'\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Activation\n",
        "from keras.optimizers import RMSprop\n",
        "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(learning_rate=0.01)) # Change optimizers to optimizer\n",
        "model.fit(x, y, batch_size=256, epochs=4)\n",
        "# Change the filename to include the .keras extension\n",
        "model.save('textgenerator.keras') # Or 'textgenerator.h5'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TrFmVmFVHBgu",
        "outputId": "4cfe0dab-f54c-4189-8518-966686395ff5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "\u001b[1m651/651\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 1.4784\n",
            "Epoch 2/4\n",
            "\u001b[1m651/651\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 1.4359\n",
            "Epoch 3/4\n",
            "\u001b[1m651/651\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 1.4055\n",
            "Epoch 4/4\n",
            "\u001b[1m651/651\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 1.3770\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sample(preds, temperature=1.0):\n",
        "  preds = np.asarray(preds).astype('float64')\n",
        "  preds = np.log(preds) / temperature\n",
        "  exp_preds = np.exp(preds)\n",
        "  preds = exp_preds / np.sum(exp_preds)\n",
        "  probas = np.random.multinomial(1, preds, 1)\n",
        "  return np.argmax(probas)"
      ],
      "metadata": {
        "id": "EENftnTqHmJU"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(length, temperature):\n",
        "    start_index = random.randint(0, len(text) - SEQ_LENGTH - 1)\n",
        "    generated = ''\n",
        "    sentence = text[start_index: start_index + SEQ_LENGTH]\n",
        "    generated += sentence\n",
        "    for i in range(length):\n",
        "        x_predictions = np.zeros((1, SEQ_LENGTH, len(characters)))\n",
        "        for t, char in enumerate(sentence):\n",
        "            x_predictions[0, t, char_to_index[char]] = 1\n",
        "\n",
        "        predictions = model.predict(x_predictions, verbose=0)[0]\n",
        "        next_index = sample(predictions,\n",
        "                                 temperature)\n",
        "        next_character = index_to_char[next_index]\n",
        "\n",
        "        generated += next_character\n",
        "        sentence = sentence[1:] + next_character\n",
        "    return generated"
      ],
      "metadata": {
        "id": "0ncLIskdHmGZ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_text(300, 0.2))\n",
        "print(generate_text(300, 0.4))\n",
        "print(generate_text(300, 0.5))\n",
        "print(generate_text(300, 0.6))\n",
        "print(generate_text(300, 0.7))\n",
        "print(generate_text(300, 0.8))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOSXHVDaHmDQ",
        "outputId": "c6592477-11ca-48d8-f5ab-4adfe915a9f0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rwick:\n",
            "can oxford, that did ever fence the sentent.\n",
            "\n",
            "king richard ii:\n",
            "and so much in the reconton, and the dead\n",
            "and man i have in the senten the recontent.\n",
            "\n",
            "romeo:\n",
            "i have a man and strength to the seasing the crown,\n",
            "and streadon my lord of sir, and stear the land\n",
            "that she to speak the true for the county\n",
            "to the world of the streech the cr\n",
            "\n",
            "why, and i challenge nothing but my duke.\n",
            "\n",
            "first untrice york:\n",
            "i lord the treaming words in a mercured the lord;\n",
            "and bear the word of the day the rest, or speak.\n",
            "\n",
            "king richard ii:\n",
            "he should not speak to the death he is and the king.\n",
            "\n",
            "romeo:\n",
            "but i cannot lord, that i am to sweet for i have not so in the county\n",
            "the sentence in life is stre\n",
            "ll cross the seas, and bid false edward are weep,\n",
            "and there shall little and lies and friends;\n",
            "and bear the demites of the forth stread,\n",
            "the bother of your seasing greated soul the word,\n",
            "in her speaking part be welcome in my soul,\n",
            "and the scrift sire to my lord of one the crown,\n",
            "command could faust in the county of all me\n",
            "and blant me to \n",
            "journey, and from nine till twelve\n",
            "is the grief of thy arm thus warwicks, the more\n",
            "to say in my as a chuss breathe and parts,\n",
            "from some treach every breathes if her were\n",
            "to seems did in a master.\n",
            "\n",
            "paulina:\n",
            "in his consmen's sight,\n",
            "and shall not be say to be less, and speaking rounto\n",
            "lest and the poor thing in my soathour.\n",
            "\n",
            "leontes:\n",
            "i know,\n",
            " their hearts: the nobles hath he fined\n",
            "or the greation, when i may the bight to me.\n",
            "she stone i on more the last and her on as?\n",
            "\n",
            "king richard ii:\n",
            "now a fair recein to put a longag on?\n",
            "\n",
            "duke of york:\n",
            "so bay me liewing king?\n",
            "\n",
            "leontes:\n",
            "as thou trumber friends, shall not know a partichours;\n",
            "and that be stay as give were mays i ,\n",
            "to said for \n",
            "at odds he weighs king richard down.\n",
            "post oxford man, now a good not! my bate.\n",
            "\n",
            "romeo:\n",
            "well, mantureth, contrax the deliar's day,\n",
            "and cause, what the rare. plantagenent and reyigntless.\n",
            "\n",
            "romeo:\n",
            "now she shall six any to the revengring for\n",
            "the decerventid so and is my lord;\n",
            "from sand in sann's flower and man, so much my sunsh.\n",
            "\n",
            "romeo:\n",
            "i hav\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U99AM5xUHmAk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1ff_JdA2Hl9_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "characters = sorted(set(text))\n",
        "char_to_index = dict((c, i) for i, c in enumerate(characters)) # Define char_to_index\n",
        "index_to_char = dict((i, c) for i, c in enumerate(characters))\n",
        "\n",
        "SEQ_LENGTH = 40\n",
        "STEP_SIZE = 3\n",
        "\n",
        "sentences = []\n",
        "next_characters = []\n",
        "\n",
        "for i in range(0, len(text) - SEQ_LENGTH, STEP_SIZE):\n",
        "    sentences.append(text[i: i + SEQ_LENGTH])  # Corrected the slicing syntax\n",
        "    next_characters.append(text[i + SEQ_LENGTH])\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "x = np.zeros((len(sentences), SEQ_LENGTH, len(characters)), dtype=bool)  # Changed np.bool to bool\n",
        "y = np.zeros((len(sentences), len(characters)), dtype=bool)\n",
        "\n",
        "for i, sentence in enumerate(sentences):\n",
        "    for t, character in enumerate(sentence):  # Iterate over the sentence instead of sentences\n",
        "        x[i, t, char_to_index[character]] = 1\n",
        "    y[i, char_to_index[next_characters[i]]] = 1"
      ],
      "metadata": {
        "id": "lhbBMd2wHZP8"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cNxf3Z88HaI8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}